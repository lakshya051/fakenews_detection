{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e518bab4",
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "\n",
        "This notebook extracts all features (network, content, user, temporal), shows feature distributions, analyzes correlations, and selects important features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d9237e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "from src import feature_extractor, data_preprocessing, network_builder, visualization\n",
        "import config\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette('Set2')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed33ac6",
      "metadata": {},
      "source": [
        "## Load Data and Build Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54372f3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = data_preprocessing.create_sample_dataset(n_samples=1000)\n",
        "\n",
        "# Build network for network features\n",
        "G = network_builder.build_interaction_graph(df, user_column=\"user_id\")\n",
        "\n",
        "# Calculate network features\n",
        "centrality_df = network_builder.calculate_centrality_measures(G)\n",
        "communities = network_builder.detect_communities(G)\n",
        "\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "print(f\"Network nodes: {G.number_of_nodes()}\")\n",
        "print(f\"Network edges: {G.number_of_edges()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e565df7",
      "metadata": {},
      "source": [
        "## Extract All Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fc4a9ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize feature extractor\n",
        "# Set use_bert=True if you have transformers installed and want BERT embeddings\n",
        "extractor = feature_extractor.FeatureExtractor(use_bert=False)\n",
        "\n",
        "# Extract content features\n",
        "print(\"Extracting content features...\")\n",
        "content_features = extractor.extract_content_features(df, text_column=\"text\")\n",
        "\n",
        "# Extract user features\n",
        "print(\"Extracting user features...\")\n",
        "user_features = extractor.extract_user_features(df, user_column=\"user_id\")\n",
        "\n",
        "# Extract temporal features\n",
        "print(\"Extracting temporal features...\")\n",
        "temporal_features = extractor.extract_temporal_features(df, timestamp_column=\"timestamp\")\n",
        "\n",
        "# Combine all features\n",
        "all_features = pd.concat([content_features, user_features, temporal_features], axis=1)\n",
        "\n",
        "print(f\"\\nTotal features extracted: {len(all_features.columns)}\")\n",
        "print(f\"\\nFeature categories:\")\n",
        "print(f\"  Content features: {len(content_features.columns)}\")\n",
        "print(f\"  User features: {len(user_features.columns)}\")\n",
        "print(f\"  Temporal features: {len(temporal_features.columns)}\")\n",
        "\n",
        "print(f\"\\n\\nFeature columns:\")\n",
        "print(all_features.columns.tolist())\n",
        "all_features.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "093e5291",
      "metadata": {},
      "source": [
        "## Add Network Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43293082",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map users to their network features\n",
        "user_to_idx = {user: idx for idx, user in enumerate(df['user_id'].unique())}\n",
        "node_mapping = {node: user_to_idx.get(node, -1) for node in G.nodes() if node in user_to_idx}\n",
        "\n",
        "# Extract network features\n",
        "network_features = extractor.extract_network_features_from_graph(\n",
        "    G,\n",
        "    node_mapping,\n",
        "    centrality_df=centrality_df,\n",
        "    communities=communities\n",
        ")\n",
        "\n",
        "# Merge network features with other features\n",
        "# Align by user_id\n",
        "df_with_features = df.copy()\n",
        "df_with_features = df_with_features.reset_index(drop=True)\n",
        "\n",
        "# Add network features\n",
        "for col in network_features.columns:\n",
        "    if col in network_features.columns:\n",
        "        # Map network features to dataframe rows\n",
        "        user_network_map = {}\n",
        "        for node, idx in node_mapping.items():\n",
        "            if idx < len(df_with_features):\n",
        "                user_network_map[df_with_features.loc[idx, 'user_id']] = network_features.loc[node, col]\n",
        "        \n",
        "        df_with_features[f'network_{col}'] = df_with_features['user_id'].map(user_network_map).fillna(0)\n",
        "\n",
        "print(f\"Added {len(network_features.columns)} network features\")\n",
        "print(f\"Total features now: {len([c for c in df_with_features.columns if c.startswith('network_') or c in all_features.columns])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d43f98",
      "metadata": {},
      "source": [
        "## Feature Distributions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f18add0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot feature distributions\n",
        "numeric_features = all_features.select_dtypes(include=[np.number])\n",
        "\n",
        "# Select key features to visualize\n",
        "key_features = ['text_length', 'word_count', 'sentiment_polarity', \n",
        "                'sentiment_compound', 'hour_of_day', 'day_of_week']\n",
        "available_features = [f for f in key_features if f in numeric_features.columns]\n",
        "\n",
        "if len(available_features) > 0:\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, col in enumerate(available_features[:6]):\n",
        "        axes[i].hist(numeric_features[col].dropna(), bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "        axes[i].set_title(col.replace('_', ' ').title(), fontweight='bold')\n",
        "        axes[i].set_xlabel('Value')\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(len(available_features), 6):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Statistics\n",
        "    print(\"Feature Statistics:\")\n",
        "    print(numeric_features[available_features].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af9fd34",
      "metadata": {},
      "source": [
        "## Feature Correlations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab037cef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot correlation matrix for key features\n",
        "key_numeric = numeric_features[available_features] if len(available_features) > 0 else numeric_features.iloc[:, :10]\n",
        "\n",
        "if len(key_numeric.columns) > 1:\n",
        "    visualization.plot_feature_correlations(key_numeric)\n",
        "    \n",
        "    # Show correlation with target\n",
        "    if 'label' in df.columns:\n",
        "        correlations = key_numeric.corrwith(df['label']).sort_values(ascending=False)\n",
        "        print(\"\\nFeature Correlations with Label:\")\n",
        "        print(\"=\"*50)\n",
        "        print(correlations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a41724c",
      "metadata": {},
      "source": [
        "## Save Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62fbef2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save extracted features for use in modeling\n",
        "features_output = pd.concat([df[['id', 'label']], all_features], axis=1)\n",
        "features_output.to_csv('../data/processed/extracted_features.csv', index=False)\n",
        "print(f\"Features saved to ../data/processed/extracted_features.csv\")\n",
        "print(f\"Total features saved: {len(all_features.columns)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
