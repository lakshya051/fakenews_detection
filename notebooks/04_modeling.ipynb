{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70228a5a",
      "metadata": {},
      "source": [
        "# Modeling\n",
        "\n",
        "This notebook trains multiple models, compares performance, performs hyperparameter tuning, analyzes feature importance, and performs error analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee286b89",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "from src import models, data_preprocessing, feature_extractor, network_builder, visualization\n",
        "import config\n",
        "\n",
        "print(\"Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43248c15",
      "metadata": {},
      "source": [
        "## Prepare Data and Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2ad925f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "print(\"Loading data...\")\n",
        "df = data_preprocessing.create_sample_dataset(n_samples=1000)\n",
        "\n",
        "# Preprocess and create splits\n",
        "print(\"Preprocessing data...\")\n",
        "train_df, val_df, test_df = data_preprocessing.preprocess_dataset(\n",
        "    df, \n",
        "    text_column=\"text\",\n",
        "    label_column=\"label\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    save_processed=False\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee54f0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features\n",
        "print(\"Extracting features...\")\n",
        "extractor = feature_extractor.FeatureExtractor(use_bert=False)\n",
        "\n",
        "# Extract features for each split\n",
        "train_features = extractor.extract_all_features(\n",
        "    train_df,\n",
        "    text_column=\"text\",\n",
        "    user_column=\"user_id\",\n",
        "    timestamp_column=\"timestamp\"\n",
        ")\n",
        "\n",
        "val_features = extractor.extract_all_features(\n",
        "    val_df,\n",
        "    text_column=\"text\",\n",
        "    user_column=\"user_id\",\n",
        "    timestamp_column=\"timestamp\"\n",
        ")\n",
        "\n",
        "test_features = extractor.extract_all_features(\n",
        "    test_df,\n",
        "    text_column=\"text\",\n",
        "    user_column=\"user_id\",\n",
        "    timestamp_column=\"timestamp\"\n",
        ")\n",
        "\n",
        "# Prepare X and y\n",
        "X_train = train_features.values\n",
        "y_train = train_df['label'].values\n",
        "X_val = val_features.values\n",
        "y_val = val_df['label'].values\n",
        "X_test = test_features.values\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Feature names: {list(train_features.columns)[:10]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da41392e",
      "metadata": {},
      "source": [
        "## Train Random Forest Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4230e343",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model = models.TraditionalMLModel(\"random_forest\", n_estimators=100, max_depth=20)\n",
        "rf_model.train(X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Evaluate\n",
        "rf_results = rf_model.evaluate(X_test, y_test)\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "print(\"=\"*50)\n",
        "for metric, value in rf_results.items():\n",
        "    if isinstance(value, (int, float)):\n",
        "        print(f\"{metric:20s}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af230419",
      "metadata": {},
      "source": [
        "## Train XGBoost Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc350c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_model = models.TraditionalMLModel(\"xgboost\", n_estimators=100, max_depth=6)\n",
        "xgb_model.train(X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Evaluate\n",
        "xgb_results = xgb_model.evaluate(X_test, y_test)\n",
        "print(\"\\nXGBoost Results:\")\n",
        "print(\"=\"*50)\n",
        "for metric, value in xgb_results.items():\n",
        "    if isinstance(value, (int, float)):\n",
        "        print(f\"{metric:20s}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdf71604",
      "metadata": {},
      "source": [
        "## Train Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c056076",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Logistic Regression\n",
        "print(\"Training Logistic Regression...\")\n",
        "lr_model = models.TraditionalMLModel(\"logistic_regression\")\n",
        "lr_model.train(X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Evaluate\n",
        "lr_results = lr_model.evaluate(X_test, y_test)\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "print(\"=\"*50)\n",
        "for metric, value in lr_results.items():\n",
        "    if isinstance(value, (int, float)):\n",
        "        print(f\"{metric:20s}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "005ffa01",
      "metadata": {},
      "source": [
        "## Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f11f80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "results = {\n",
        "    \"Random Forest\": rf_results,\n",
        "    \"XGBoost\": xgb_results,\n",
        "    \"Logistic Regression\": lr_results\n",
        "}\n",
        "\n",
        "# Plot comparison\n",
        "visualization.plot_model_comparison(results, metric=\"f1\")\n",
        "visualization.plot_model_comparison(results, metric=\"accuracy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "961b3278",
      "metadata": {},
      "source": [
        "## Confusion Matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200eaa72",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrices for all models\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "visualization.plot_confusion_matrix(y_test, y_pred_rf, class_names=[\"Real\", \"Fake\"])\n",
        "\n",
        "print(\"\\nXGBoost Confusion Matrix:\")\n",
        "visualization.plot_confusion_matrix(y_test, y_pred_xgb, class_names=[\"Real\", \"Fake\"])\n",
        "\n",
        "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
        "visualization.plot_confusion_matrix(y_test, y_pred_lr, class_names=[\"Real\", \"Fake\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e7c640",
      "metadata": {},
      "source": [
        "## ROC Curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f9bc04",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ROC curves\n",
        "y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
        "y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "y_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "visualization.plot_roc_curve(y_test, y_proba_rf, \"Random Forest\")\n",
        "visualization.plot_roc_curve(y_test, y_proba_xgb, \"XGBoost\")\n",
        "visualization.plot_roc_curve(y_test, y_proba_lr, \"Logistic Regression\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fa1ab20",
      "metadata": {},
      "source": [
        "## Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07b5f9dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot feature importance for Random Forest\n",
        "feature_names = train_features.columns.tolist()\n",
        "visualization.plot_feature_importance(rf_model.model, feature_names, top_n=15)\n",
        "\n",
        "# Show top features\n",
        "importances = rf_model.model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1][:15]\n",
        "print(\"\\nTop 15 Most Important Features:\")\n",
        "print(\"=\"*50)\n",
        "for i in indices:\n",
        "    print(f\"{feature_names[i]:30s}: {importances[i]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20116fa9",
      "metadata": {},
      "source": [
        "## Save Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64c6eee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best performing model\n",
        "best_model = xgb_model if xgb_results['f1'] > rf_results['f1'] else rf_model\n",
        "best_model_name = \"XGBoost\" if xgb_results['f1'] > rf_results['f1'] else \"Random Forest\"\n",
        "\n",
        "model_path = Path(\"../models/best_model.pkl\")\n",
        "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "best_model.save(model_path)\n",
        "\n",
        "print(f\"Saved best model ({best_model_name}) to {model_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
